{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPKEumNq3orUeMjRRaOSM0"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import sentencepiece as spm\n",
        "import math\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "1MXsGuevaVRw"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "!kaggle datasets download -d rmisra/news-category-dataset\n",
        "!unzip news-category-dataset.zip"
      ],
      "metadata": {
        "id": "IJA6l6aAabby",
        "outputId": "c1c901e2-4cee-4593-9828-8deb4de80f82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.5)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n",
            "Dataset URL: https://www.kaggle.com/datasets/rmisra/news-category-dataset\n",
            "License(s): Attribution 4.0 International (CC BY 4.0)\n",
            "Downloading news-category-dataset.zip to /content\n",
            " 34% 9.00M/26.5M [00:00<00:00, 44.5MB/s]\n",
            "100% 26.5M/26.5M [00:00<00:00, 100MB/s] \n",
            "Archive:  news-category-dataset.zip\n",
            "  inflating: News_Category_Dataset_v3.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dZ0m40SUZer5",
        "outputId": "180f830a-da91-4bc2-d71a-024431266af1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            headline   category  \\\n",
              "0  Over 4 Million Americans Roll Up Sleeves For O...  U.S. NEWS   \n",
              "1  American Airlines Flyer Charged, Banned For Li...  U.S. NEWS   \n",
              "2  23 Of The Funniest Tweets About Cats And Dogs ...     COMEDY   \n",
              "3  The Funniest Tweets From Parents This Week (Se...  PARENTING   \n",
              "4  Woman Who Called Cops On Black Bird-Watcher Lo...  U.S. NEWS   \n",
              "\n",
              "                                   short_description               authors  \\\n",
              "0  Health experts said it is too early to predict...  Carla K. Johnson, AP   \n",
              "1  He was subdued by passengers and crew when he ...        Mary Papenfuss   \n",
              "2  \"Until you have a dog you don't understand wha...         Elyse Wanshel   \n",
              "3  \"Accidentally put grown-up toothpaste on my to...      Caroline Bologna   \n",
              "4  Amy Cooper accused investment firm Franklin Te...        Nina Golgowski   \n",
              "\n",
              "        date  \n",
              "0 2022-09-23  \n",
              "1 2022-09-23  \n",
              "2 2022-09-23  \n",
              "3 2022-09-23  \n",
              "4 2022-09-22  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cf22edd5-26c4-46ca-804d-44d0030be16b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>category</th>\n",
              "      <th>short_description</th>\n",
              "      <th>authors</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Over 4 Million Americans Roll Up Sleeves For O...</td>\n",
              "      <td>U.S. NEWS</td>\n",
              "      <td>Health experts said it is too early to predict...</td>\n",
              "      <td>Carla K. Johnson, AP</td>\n",
              "      <td>2022-09-23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>American Airlines Flyer Charged, Banned For Li...</td>\n",
              "      <td>U.S. NEWS</td>\n",
              "      <td>He was subdued by passengers and crew when he ...</td>\n",
              "      <td>Mary Papenfuss</td>\n",
              "      <td>2022-09-23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
              "      <td>COMEDY</td>\n",
              "      <td>\"Until you have a dog you don't understand wha...</td>\n",
              "      <td>Elyse Wanshel</td>\n",
              "      <td>2022-09-23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
              "      <td>PARENTING</td>\n",
              "      <td>\"Accidentally put grown-up toothpaste on my to...</td>\n",
              "      <td>Caroline Bologna</td>\n",
              "      <td>2022-09-23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Woman Who Called Cops On Black Bird-Watcher Lo...</td>\n",
              "      <td>U.S. NEWS</td>\n",
              "      <td>Amy Cooper accused investment firm Franklin Te...</td>\n",
              "      <td>Nina Golgowski</td>\n",
              "      <td>2022-09-22</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cf22edd5-26c4-46ca-804d-44d0030be16b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cf22edd5-26c4-46ca-804d-44d0030be16b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cf22edd5-26c4-46ca-804d-44d0030be16b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c22275de-9af9-445c-b650-20c63243a465\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c22275de-9af9-445c-b650-20c63243a465')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c22275de-9af9-445c-b650-20c63243a465 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# https://www.kaggle.com/datasets/rmisra/news-category-dataset/data\n",
        "\n",
        "directory = \"./News_Category_Dataset_v3.json\"\n",
        "data = pd.read_json(directory, lines=True)\n",
        "data = data.drop('link', axis=1)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(\n",
        "    df: pd.DataFrame,\n",
        "    bos_token: int,\n",
        "    eos_token: int,\n",
        "    mean: float = None,\n",
        "    std:float = None\n",
        "    ):\n",
        "  \"\"\" Tokenize dataframe in the form\n",
        "\n",
        "      | headline |\tcategory |\tshort_description |\tauthors |\tdate |\n",
        "            ||          ||              ||             ||       ||\n",
        "      sentencepiece  index-based   sentencepiece  index-based  Normalized\n",
        "\n",
        "  Args:\n",
        "      df: The dataframe to Tokenize.\n",
        "      mean: Mean for normalization of date.\n",
        "      std: Standard deviation for normalization of date.\n",
        "\n",
        "  Returns:\n",
        "      The tokenized dataframe.\n",
        "  \"\"\"\n",
        "\n",
        "  categories         = df.category.unique().tolist()\n",
        "  category_tokens_ix = dict(enumerate(categories))\n",
        "  category_tokens_xi = {x:i for i, x in category_tokens_ix.items()}\n",
        "\n",
        "  authors           = df.authors.unique().tolist()\n",
        "  authors_tokens_ix = dict(enumerate(authors))\n",
        "  authors_tokens_xi = {x:i for i, x in authors_tokens_ix.items()}\n",
        "\n",
        "  print(\"Total number of categories:\", len(category_tokens_ix))\n",
        "  print(\"Total number of Authors:\",    len(authors_tokens_ix))\n",
        "\n",
        "  df['date']    = (df['date'] - df['date'].min()).dt.total_seconds()\n",
        "\n",
        "  mean = mean if mean else df['date'].mean()\n",
        "  std  = std if std else df['date'].std()\n",
        "\n",
        "  print('Using mean as {} for date'.format(mean))\n",
        "  print('Using std as {} for date'.format(std))\n",
        "\n",
        "  df['date']              = (df['date'] - mean)/std\n",
        "  df['category']          = df['category'].map(category_tokens_xi)\n",
        "  df['authors']           = df['authors'].map(authors_tokens_xi)\n",
        "  df['headline']          = df['headline'].map(lambda x: [bos_token] + sp.encode_as_ids(x) + [eos_token])\n",
        "  df['short_description'] = df['short_description'].map(lambda x: [bos_token] + sp.encode_as_ids(x) + [eos_token])\n",
        "\n",
        "  return df, category_tokens_ix, authors_tokens_ix, mean, std, (len(category_tokens_ix),\n",
        "                                                                len(authors_tokens_ix))"
      ],
      "metadata": {
        "id": "_-CWMhyZamBq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_dataset(df: pd.DataFrame, PAD_TOKEN: int):\n",
        "  \"\"\"Pads the headline and short_description columns of the dataframe with the given pad token.\n",
        "\n",
        "  Args:\n",
        "      df: The dataframe to pad.\n",
        "      pad_token: The token to use for padding.\n",
        "\n",
        "  Returns:\n",
        "      The padded dataframe.\n",
        "  \"\"\"\n",
        "  MAX_HEADLINE_LENGHT       = df['headline'].str.len().max()\n",
        "  MAX_SHORT_DESCRIPTION_LEN = df['short_description'].str.len().max()\n",
        "\n",
        "  print(\"Maxlen for headline:\", MAX_HEADLINE_LENGHT)\n",
        "  print(\"Maxlen for short_description:\", MAX_SHORT_DESCRIPTION_LEN)\n",
        "\n",
        "  df['headline'] = df['headline'].map(lambda x: x + [PAD_TOKEN] * (MAX_HEADLINE_LENGHT - len(x)))\n",
        "  df['short_description'] = df['short_description'].map(lambda x: x + [PAD_TOKEN] * (MAX_SHORT_DESCRIPTION_LEN - len(x)))\n",
        "\n",
        "  return df, MAX_HEADLINE_LENGHT, MAX_SHORT_DESCRIPTION_LEN\n"
      ],
      "metadata": {
        "id": "BB6QO8jHawJd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def block_dataset(df: pd.DataFrame,\n",
        "                  blocksize: int,\n",
        "                  maxlen: int,\n",
        "                  pad_token: int\n",
        "                  ):\n",
        "\n",
        "  context = torch.ones(len(df), maxlen, blocksize, dtype=torch.int32) * pad_token\n",
        "  target = torch.ones(len(df), maxlen-1, dtype=torch.int32) * pad_token\n",
        "\n",
        "  for i, row in enumerate(df['short_description']):\n",
        "    for j in range(maxlen-1):\n",
        "      context[i, j+1] = torch.concat([context[i, j, 1:], torch.tensor([row[j]])])\n",
        "      target[i, j] = row[j+1]\n",
        "\n",
        "  context = context[:, 1:].reshape(-1, blocksize)\n",
        "  target = target.reshape(-1)\n",
        "\n",
        "  df = df.loc[df.index.repeat([maxlen-1] * len(df))].reset_index(drop=True)\n",
        "  df['context'] = context.tolist()\n",
        "  df['target'] = target.tolist()\n",
        "\n",
        "  return df\n"
      ],
      "metadata": {
        "id": "tolKqIVFbH6U"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -o m.vocab https://raw.githubusercontent.com/messi10tom/Fake-news-Generator/main/m.vocab\n",
        "!curl -o m.model https://raw.githubusercontent.com/messi10tom/Fake-news-Generator/main/m.model"
      ],
      "metadata": {
        "id": "KeBfnQ7ha0RR",
        "outputId": "78865d7a-f0ee-4d28-8ff1-23390f4b49a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 88432  100 88432    0     0   211k      0 --:--:-- --:--:-- --:--:--  211k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  313k  100  313k    0     0   799k      0 --:--:-- --:--:-- --:--:--  800k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sp = spm.SentencePieceProcessor()\n",
        "sp.load('m.model')\n",
        "\n",
        "# dataset, token_category, token_author, mean, std, vocabsizes = encode(data.copy(),\n",
        "#                                                                         sp.bos_id(),\n",
        "#                                                                        sp.eos_id())\n",
        "# dataset, maxlen_H, maxlen_S = pad_dataset(dataset, sp.unk_id())"
      ],
      "metadata": {
        "id": "-E0hm9bha2rE",
        "outputId": "21e7cdcd-cde0-4e37-ed73-4d1591c828c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FN_Dataset(Dataset):\n",
        "    \"\"\"  Fake News dataset \"\"\"\n",
        "    def __init__(self,\n",
        "                 df: pd.DataFrame,\n",
        "                 bos_token: int,\n",
        "                 eos_token: int,\n",
        "                 pad_token: int,\n",
        "                 mean: float = None,\n",
        "                 std:float = None\n",
        "                 ):\n",
        "      \"\"\"\n",
        "\n",
        "      Args:\n",
        "        df              : Dataframe containing the data.\n",
        "        bos_token       : Beginning of sentence token.\n",
        "        eos_token       : End of sentence token.\n",
        "        pad_token       : Padding token.\n",
        "        mean(Optional)  : Mean for normalization of date.\n",
        "        std(Optional)   : Standard deviation for normalization of date.\n",
        "\n",
        "      \"\"\"\n",
        "\n",
        "      super().__init__()\n",
        "\n",
        "      self.df, self.Category_decoder, self.Author_decoder, self.mean, self.std, self.vocabsizes = encode(df, bos_token, eos_token, mean, std)\n",
        "      self.df, self.maxlen_H, self.maxlen_S = pad_dataset(self.df, pad_token)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      sample = self.df.iloc[idx]\n",
        "\n",
        "      return ({\n",
        "          'headline': torch.tensor(sample['headline']),\n",
        "          'date': torch.tensor([sample['date']]).to(torch.float32),\n",
        "          'category': torch.tensor(sample['category']),\n",
        "          'authors': torch.tensor(sample['authors'])\n",
        "      }, torch.tensor(sample['short_description']))"
      ],
      "metadata": {
        "id": "tqUVh-WjbBrL"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self,\n",
        "                 d_model: int,\n",
        "                 dropout: float,\n",
        "                 max_len: int\n",
        "                 ):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          d_model: Dimension of the embedding.\n",
        "          dropout: Dropout rate.\n",
        "          max_len: Maximum length of the sequence.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        pos_encoding = torch.zeros(max_len, d_model)\n",
        "        positions_list = torch.arange(0,\n",
        "                                      max_len,\n",
        "                                      dtype=torch.float).view(-1, 1) # 0, 1, 2, 3, 4, 5\n",
        "\n",
        "        division_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0)) / d_model) # 1000^(2i/dim_model)\n",
        "\n",
        "        # PE(pos, 2i) = sin(pos/1000^(2i/dim_model))\n",
        "        pos_encoding[:, 0::2] = torch.sin(positions_list * division_term)\n",
        "\n",
        "        # PE(pos, 2i + 1) = cos(pos/1000^(2i/dim_model))\n",
        "        pos_encoding[:, 1::2] = torch.cos(positions_list * division_term)\n",
        "\n",
        "        # Saving buffer (same as parameter without gradients needed)\n",
        "        pos_encoding = pos_encoding.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer(\"pos_encoding\",pos_encoding)\n",
        "\n",
        "    def forward(self, token_embedding: torch.tensor) -> torch.tensor:\n",
        "        # Residual connection + pos encoding\n",
        "        return self.dropout(token_embedding + self.pos_encoding[:token_embedding.size(0), :])"
      ],
      "metadata": {
        "id": "PZj-OTtycLJu"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FN_Generator(nn.Module):\n",
        "    \"\"\" Generate short_description \"\"\"\n",
        "    def __init__(self,\n",
        "                 output_dim: int,\n",
        "                 embed_dim: int,\n",
        "                 headline_vocabsize: int,\n",
        "                 inputsize_H: int,\n",
        "                 inputsize_S: int,\n",
        "                 cat_vocabsize: int,\n",
        "                 auth_vocabsize: int,\n",
        "                 d_model: int = 512,\n",
        "                 nhead: int = 8,\n",
        "                 num_encoder_layers: int = 6,\n",
        "                 num_decoder_layers: int = 6,\n",
        "                 dropout: float = 0.1\n",
        "                 ) -> None:\n",
        "\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          output_dim          : Dimension of the output.\n",
        "          embed_dim           : Dimension of the embedding.\n",
        "          headline_vocabsize  : Vocabulary size of the headline.\n",
        "          inputsize_H         : Input size of the headline.\n",
        "          inputsize_S         : Input size of the short_description.\n",
        "          cat_vocabsize       : Vocabulary size of the category.\n",
        "          auth_vocabsize      : Vocabulary size of the authors.\n",
        "          d_model             : Dimension of the Transformer.\n",
        "          nhead               : Number of heads.\n",
        "          num_encoder_layers  : Number of encoder layers.\n",
        "          num_decoder_layers  : Number of decoder layers.\n",
        "          dropout             : Dropout rate.\n",
        "\n",
        "        \"\"\"\n",
        "        super(FN_Generator, self).__init__()\n",
        "\n",
        "        self.positional_encoder = PositionalEncoding(d_model=d_model,\n",
        "                                                     dropout=dropout,\n",
        "                                                     max_len=5000)\n",
        "\n",
        "        self.embed_headline    = nn.Embedding(headline_vocabsize, embed_dim)\n",
        "        self.embed_cat         = nn.Embedding(cat_vocabsize, embed_dim)\n",
        "        self.embed_auth        = nn.Embedding(auth_vocabsize, embed_dim)\n",
        "        self.embed_desc     = nn.Embedding(headline_vocabsize, embed_dim)\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.droupout = nn.Dropout(p=dropout)\n",
        "\n",
        "        self.Wd = nn.Linear(1, d_model)\n",
        "        self.Wh = nn.Linear(inputsize_H * embed_dim, d_model)\n",
        "        self.Wc = nn.Linear(embed_dim, d_model)\n",
        "        self.Wa = nn.Linear(embed_dim, d_model)\n",
        "        self.Ws = nn.Linear(inputsize_S * embed_dim, d_model)\n",
        "\n",
        "        self.transformer = nn.Transformer(d_model=d_model,\n",
        "                                          nhead=nhead,\n",
        "                                          num_encoder_layers=num_encoder_layers,\n",
        "                                          num_decoder_layers=num_decoder_layers,\n",
        "                                          dropout=dropout\n",
        "                                         )\n",
        "\n",
        "        self.output = nn.Linear(d_model, output_dim)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        EMB_h    = self.embed_headline(src['headline'])\n",
        "        EMB_c    = self.embed_cat(src['category'])\n",
        "        EMB_a    = self.embed_auth(src['authors'])\n",
        "        EMB_s    = self.embed_desc(tgt)\n",
        "\n",
        "        EMB_h = self.flatten(EMB_h)\n",
        "        EMB_s = self.flatten(EMB_s)\n",
        "\n",
        "\n",
        "        lin = self.droupout(torch.relu(self.Wh(EMB_h) +\n",
        "                                      self.Wc(EMB_c) +\n",
        "                                      self.Wa(EMB_a) +\n",
        "                                      self.Wd(src['date'])\n",
        "                                      ))\n",
        "\n",
        "        lin = self.positional_encoder(lin)\n",
        "        out = self.transformer(lin, self.Ws(EMB_s))\n",
        "\n",
        "\n",
        "        return torch.softmax(self.output(out), dim=1)"
      ],
      "metadata": {
        "id": "JEVTCh-cef0-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = FN_Dataset(df=data.copy(),\n",
        "                     bos_token=sp.bos_id(),\n",
        "                     eos_token=sp.eos_id(),\n",
        "                     pad_token=sp.unk_id()\n",
        "                     )\n",
        "dataloader = DataLoader(dataset, batch_size=32,\n",
        "                        shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQiiktaswxjG",
        "outputId": "0a65fa8a-9ea7-45d6-e64e-2d18ffb08734"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of categories: 42\n",
            "Total number of Authors: 29169\n",
            "Using mean as 102645854.34430885 for date\n",
            "Using std as 65527224.61900345 for date\n",
            "Maxlen for headline: 187\n",
            "Maxlen for short_description: 419\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"\n",
        "Args:\n",
        "  output_dim          : Dimension of the output.\n",
        "  embed_dim           : Dimension of the embedding.\n",
        "  headline_vocabsize  : Vocabulary size of the headline.\n",
        "  inputsize_H         : Input size of the headline.\n",
        "  inputsize_S         : Input size of the short_description.\n",
        "  cat_vocabsize       : Vocabulary size of the category.\n",
        "  auth_vocabsize      : Vocabulary size of the authors.\n",
        "  d_model             : Dimension of the Transformer.\n",
        "  nhead               : Number of heads.\n",
        "  num_encoder_layers  : Number of encoder layers.\n",
        "  num_decoder_layers  : Number of decoder layers.\n",
        "  dropout             : Dropout rate.\n",
        "\n",
        "\"\"\"\n",
        "generator = FN_Generator(output_dim=sp.vocab_size(),\n",
        "                         embed_dim=8,\n",
        "                         headline_vocabsize=sp.vocab_size(),\n",
        "                         inputsize_H=dataset.maxlen_H,\n",
        "                         inputsize_S=dataset.maxlen_S,\n",
        "                         cat_vocabsize=dataset.vocabsizes[0],\n",
        "                         auth_vocabsize=dataset.vocabsizes[1])"
      ],
      "metadata": {
        "id": "RAwZaFapwPJr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce5f12e3-5be2-4a83-a788-df20a66525cc"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:307: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src, tgt = next(iter(dataloader))"
      ],
      "metadata": {
        "id": "mHeP5xSk0IVx"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "src"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoYMrdEwMQ3G",
        "outputId": "abe6eb0d-cfdb-42dc-d4a1-bc7bd11bda68"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'headline': tensor([[   1,  471, 3160,  ...,    0,    0,    0],\n",
              "         [   1,   40, 2288,  ...,    0,    0,    0],\n",
              "         [   1,  258,  671,  ...,    0,    0,    0],\n",
              "         ...,\n",
              "         [   1,  803,    7,  ...,    0,    0,    0],\n",
              "         [   1,  281,  654,  ...,    0,    0,    0],\n",
              "         [   1, 3894,   13,  ...,    0,    0,    0]]),\n",
              " 'date': tensor([[ 1.0759],\n",
              "         [ 1.0746],\n",
              "         [ 0.0698],\n",
              "         [ 0.7331],\n",
              "         [ 0.8227],\n",
              "         [ 1.1880],\n",
              "         [ 1.9132],\n",
              "         [ 0.5986],\n",
              "         [ 0.0158],\n",
              "         [ 0.0949],\n",
              "         [ 0.5326],\n",
              "         [ 1.4293],\n",
              "         [-1.4122],\n",
              "         [ 1.1919],\n",
              "         [ 0.6447],\n",
              "         [ 0.9005],\n",
              "         [-0.0857],\n",
              "         [ 0.8926],\n",
              "         [ 0.3560],\n",
              "         [ 1.9633],\n",
              "         [-1.2672],\n",
              "         [-0.6593],\n",
              "         [ 0.1094],\n",
              "         [ 1.1075],\n",
              "         [-1.4887],\n",
              "         [-1.2896],\n",
              "         [ 0.7054],\n",
              "         [ 0.5617],\n",
              "         [-0.8360],\n",
              "         [ 0.0593],\n",
              "         [ 0.5392],\n",
              "         [-0.8043]]),\n",
              " 'category': tensor([ 8, 19,  8,  8,  8, 34,  0,  8, 21,  7,  8,  7, 23,  9, 30,  9, 29,  8,\n",
              "          6,  7, 16, 28,  8, 19, 16, 10,  7, 36, 10, 39, 15, 14]),\n",
              " 'authors': tensor([ 2447,    82, 12509,   613,    66,  2661,     5,   170, 13705, 10054,\n",
              "             5,     2, 20503,    89,     3,  1352,  9925,   554,    34,  1268,\n",
              "         11243,     5,  1413,    58, 28186, 11872,    42,     5,     5, 10968,\n",
              "          9353, 22673])}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator(sample).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "8eOA2p0Ww2C6",
        "outputId": "d868ef5a-5e83-4e58-b32c-42e4a22a7c4a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "FN_Generator.forward() missing 1 required positional argument: 'tgt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-9c8e4c6b717c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: FN_Generator.forward() missing 1 required positional argument: 'tgt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "crossentropy = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(generator.parameters(), lr=0.005)"
      ],
      "metadata": {
        "id": "jUF8wc3k0Ueo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1):\n",
        "    for i, ds in enumerate(dataloader):\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        output = generator(ds)\n",
        "        loss = crossentropy(output, ds['target'])\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print('Epoch',epoch,' Loss -->',loss.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "GWGCvJzQ0NpN",
        "outputId": "505a2ec4-e362-4db0-c0a3-a0296cd175cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-b3748bcc2be9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' Loss -->'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    519\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             )\n\u001b[0;32m--> 521\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    770\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}